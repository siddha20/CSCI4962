{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "For this task, I will still be using the data about peoples age, gender, salary\n",
    "and whether or not they purcahsed a vehicle. Instead of using logistic\n",
    "regression, a decision tree will be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>AnnualSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>681</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>43500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>353</td>\n",
       "      <td>Male</td>\n",
       "      <td>49</td>\n",
       "      <td>74000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>107500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>661</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>79000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>863</td>\n",
       "      <td>Male</td>\n",
       "      <td>38</td>\n",
       "      <td>59000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>800</td>\n",
       "      <td>Female</td>\n",
       "      <td>47</td>\n",
       "      <td>23500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>407</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>138500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>299</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>134000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>687</td>\n",
       "      <td>Female</td>\n",
       "      <td>44</td>\n",
       "      <td>73500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User ID  Gender  Age  AnnualSalary  Purchased\n",
       "0        385    Male   35         20000          0\n",
       "1        681    Male   40         43500          0\n",
       "2        353    Male   49         74000          0\n",
       "3        895    Male   40        107500          1\n",
       "4        661    Male   25         79000          0\n",
       "..       ...     ...  ...           ...        ...\n",
       "995      863    Male   38         59000          0\n",
       "996      800  Female   47         23500          0\n",
       "997      407  Female   28        138500          1\n",
       "998      299  Female   48        134000          1\n",
       "999      687  Female   44         73500          0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "df = pd.read_csv(\"car_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 99.5%\n",
      "precision: 100.0%\n",
      "recall: 98.75621890547264%\n",
      "cv avg score 0.8799999999999999\n",
      "test_point: [[53, 0, 60000]], result: [1.]\n",
      "test_point: [[53, 1, 60000]], result: [1.]\n",
      "test_point: [[20, 1, 100000]], result: [0.]\n",
      "test_point: [[60, 1, 100000]], result: [1.]\n",
      "test_point: [[20, 1, 200000]], result: [1.]\n"
     ]
    }
   ],
   "source": [
    "def metric(pred, act):\n",
    "    assert(pred.shape[0] == act.shape[0])\n",
    "    N = pred.shape[0]   \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for n in range(N):\n",
    "        if (pred[n] ==  1 and act[n] == 1):\n",
    "            tp += 1\n",
    "        if (pred[n] == 0 and act[n] == 0):\n",
    "            tn += 1\n",
    "        if(pred[n] == 1 and act[n] == 0):\n",
    "            fp += 1\n",
    "        if(pred[n] == 0 and act[n] == 1):\n",
    "            fn += 1\n",
    "    acc = (tp + tn)/(tp + tn + fp + fn)\n",
    "    prec = (tp)/(tp + fp)\n",
    "    rec = (tp)/(tp + fn) \n",
    "    return (acc, prec, rec)\n",
    "\n",
    "age = (np.asarray(df[\"Age\"], dtype=np.float64))\n",
    "gen = (np.asarray([df[\"Gender\"] == \"Female\"], dtype=np.float64) * 1)\n",
    "salary = (np.asarray(df[\"AnnualSalary\"], dtype=np.float64))\n",
    "X = np.vstack((age, gen, salary)).T\n",
    "\n",
    "P = np.asarray(df[\"Purchased\"], dtype=np.float64)\n",
    "N = np.size(P)\n",
    "P = P.reshape(N, 1)\n",
    "\n",
    "# use decision tree classifier\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X, P)\n",
    "P_pred = dtree.predict(X)\n",
    "\n",
    "# perform 5-fold cross validation\n",
    "scores = cross_val_score(dtree, X, P.flatten(), n_jobs=-1)\n",
    "\n",
    "# collect metrics\n",
    "acc, prec, rec = metric(P_pred, P)\n",
    "\n",
    "# print results\n",
    "print(\"accuracy: {}%\".format(acc*100))\n",
    "print(\"precision: {}%\".format(prec*100))\n",
    "print(\"recall: {}%\".format(rec*100))\n",
    "print(\"cv avg score {}\".format(np.mean(scores)))\n",
    "\n",
    "# change input parameters\n",
    "test_point = [[53, 0, 60000]]\n",
    "print(f\"test_point: {test_point}, result: {dtree.predict(test_point)}\")\n",
    "test_point = [[53, 1, 60000]]\n",
    "print(f\"test_point: {test_point}, result: {dtree.predict(test_point)}\")\n",
    "test_point = [[20, 1, 100000]]\n",
    "print(f\"test_point: {test_point}, result: {dtree.predict(test_point)}\")\n",
    "test_point = [[60, 1, 100000]]\n",
    "print(f\"test_point: {test_point}, result: {dtree.predict(test_point)}\")\n",
    "test_point = [[20, 1, 200000]]\n",
    "print(f\"test_point: {test_point}, result: {dtree.predict(test_point)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, with the two inputs (53, 0, 60000) and (53, 1, 60000),\n",
    "the first purchases a car, and the second does not. The only difference between\n",
    "these inputs is that the first one is male, and the second one is female.\n",
    "Somewhere in the decision tree, a node distinguishes between male and female\n",
    "(there may be more than one) and will cause the output seen above. \n",
    "\n",
    "Take the two inputs (20, 1, 100000) and (60, 1, 100000). Here we differ in the\n",
    "age of the person. The 20-year-old does not buy the car, but the 60-year-old\n",
    "does. Similar to gender, there will be a node in the decision tree which causes\n",
    "the 20-year-old to lead to a result of 0 and the 60-year-old to a result of 1.\n",
    "However, take the input (20, 1, 200000), which results in 1; possibly, higher\n",
    "in the tree, there is a node that sees a salary of 200000 to be greater than a\n",
    "certain threshold and will classify the person as purchasing the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "I used two bagging methods, bagging with SVM and random forest. I used one boosting method, AdaBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 75.7%\n",
      "precision: 86.63594470046083%\n",
      "recall: 46.766169154228855%\n",
      "cv avg score 0.754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# use bagging with svm\n",
    "svm_bag = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0)\n",
    "svm_bag = svm_bag.fit(X, P.flatten())\n",
    "P_pred = svm_bag.predict(X)\n",
    "\n",
    "# perform 5-fold cross validation\n",
    "scores = cross_val_score(svm_bag, X, P.flatten(), n_jobs=-1)\n",
    "\n",
    "# print results\n",
    "acc, prec, rec = metric(P_pred, P)\n",
    "print(\"accuracy: {}%\".format(acc*100))\n",
    "print(\"precision: {}%\".format(prec*100))\n",
    "print(\"recall: {}%\".format(rec*100))\n",
    "print(\"cv avg score {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.6%\n",
      "precision: 98.2587064676617%\n",
      "recall: 98.2587064676617%\n",
      "cv avg score 0.8859999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# use random forest, a bagging method\n",
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf = rf.fit(X, P.flatten())\n",
    "P_pred = rf.predict(X)\n",
    "\n",
    "# perform 5-fold cross validation\n",
    "scores = cross_val_score(rf, X, P.flatten(), n_jobs=-1)\n",
    "\n",
    "# print results\n",
    "acc, prec, rec = metric(P_pred, P)\n",
    "print(\"accuracy: {}%\".format(acc*100))\n",
    "print(\"precision: {}%\".format(prec*100))\n",
    "print(\"recall: {}%\".format(rec*100))\n",
    "print(\"cv avg score {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 90.60000000000001%\n",
      "precision: 90.31413612565446%\n",
      "recall: 85.82089552238806%\n",
      "cv avg score 0.8870000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# use adaboost, a boosting method\n",
    "adaboost = AdaBoostClassifier(n_estimators=100)\n",
    "adaboost =  adaboost.fit(X, P.flatten())\n",
    "P_pred = adaboost.predict(X)\n",
    "\n",
    "# perform 5-fold cross validation\n",
    "scores = cross_val_score(adaboost, X, P.flatten(), n_jobs=-1)\n",
    "\n",
    "# print results\n",
    "acc, prec, rec = metric(P_pred, P)\n",
    "print(\"accuracy: {}%\".format(acc*100))\n",
    "print(\"precision: {}%\".format(prec*100))\n",
    "print(\"recall: {}%\".format(rec*100))\n",
    "print(\"cv avg score {}\".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results of the classifiers, we can see that random forests and\n",
    "AdaBoost did significantly better than bagging SVMs. Moreover, bagging SVMs had\n",
    "the worst CV score, while the CV score for both random forest and AdaBoost was\n",
    "reasonably high. Additionally, I expected to see the accuracy of random forests\n",
    "lower than AdaBoost because the boosting method aims to reduce bias, but the\n",
    "accuracy for the random forest was higher. Similarly, I expected the CV score\n",
    "for the random forest to be higher because it is boosting method, and while it\n",
    "is higher, it is very close to AdaBoost. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "From the four classification models used above, the mean cross-validation score\n",
    "can be used to judge the generalization of each model. The model that best\n",
    "generalizes the best is random forest, the second best is AdaBoost, the third\n",
    "best is decision tree, and the fourth best is bagging SVMs. This is somewhat\n",
    "consistent with what I expected. Mainly, I expected random forest to generalize\n",
    "well because it is a bagging method, and it did. \n",
    "\n",
    "For each of the models, accuracy, precision, and recall are displayed. When\n",
    "selling a car, it is not a big deal if I predict someone will buy a car and the\n",
    "actually do not (false positive). However, if I predict someone will not\n",
    "purchase a car and they actually would (false negative), I lose money (bad). As\n",
    "a result, I am interested in the recall metric, which is sensitive to the\n",
    "number of false negatives ($\\frac{TP}{TP + FN}$). \n",
    "\n",
    "Looking at the recalls for each model, the decision tree did the best, random\n",
    "forest second best, AdaBoost third best, and bagging SVMs last. Even though the\n",
    "decision tree did the best, I would still deploy the random forest model\n",
    "because it is more likely to generalize better. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b4957a3169536379e8f75f7e9878614f7937738a9df979092ace7c23c9fbae51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
